interface FSItem { // define structure describing a file-system entry returned by puter
    id: string; // unique id of this fs item used for internal referencing
    uid: string; // user id of the owner to determine ownership
    name: string; // display name for the file or directory
    path: string; // full storage path so the item can be accessed
    is_dir: boolean; // flag telling whether this entry is a folder
    parent_id: string; // id of the parent entry for building directory trees
    parent_uid: string; // owner id of the parent entry for permission checks
    created: number; // timestamp of when this entry was created
    modified: number; // timestamp of the last modification
    accessed: number; // timestamp of the last read access
    size: number | null; // file size for normal files, null for directories
    writable: boolean; // permission flag indicating whether user can modify it
}

interface PuterUser { // define structure of a user object returned by puter auth
    uuid: string; // unique identifier for the authenticated user
    username: string; // username chosen by the user for identification
}

interface KVItem { // define structure for entries stored in key-value storage
    key: string; // lookup key to retrieve stored data
    value: string; // raw stored value in serialized string form
}

interface ChatMessageContent { // define shape of messages that contain mixed content types
    type: "file" | "text"; // specify whether message content represents a file or plain text
    puter_path?: string; // optional path pointing to a stored file when type is "file"
    text?: string; // optional text payload when type is "text"
}

interface ChatMessage { // define structure of messages exchanged with AI service
    role: "user" | "assistant" | "system"; // specify actor producing the message
    content: string | ChatMessageContent[]; // allow plain text or structured mixed content messages
}

interface PuterChatOptions { // define configuration options used when invoking the AI chat endpoint
    model?: string; // optional model selection to choose AI variant
    stream?: boolean; // flag enabling incremental streaming responses
    max_tokens?: number; // upper limit on the number of tokens generated by AI
    temperature?: number; // randomness factor influencing response variety
    tools?: { // optional list of callable function tools exposed to AI
        type: "function"; // tool type is always a function callable by AI
        function: {
            name: string; // name of the tool function AI may call
            description: string; // explanation of what the function does
            parameters: { type: string; properties: {} }; // shape definition for function parameters
        }[];
    };
}

interface AIResponse { // define structure of data returned from a puter AI chat call
    index: number; // response index for multi-message outputs
    message: { // container holding main AI message payload
        role: string; // role of AI response, usually "assistant"
        content: string | any[]; // raw text or structured content returned by AI
        refusal: null | string; // message indicating refusal when AI declines a task
        annotations: any[]; // additional annotation info from AI processing
    };
    logprobs: null | any; // optional probability metadata returned when enabled
    finish_reason: string; // indicator describing why the AI stopped generating
    usage: { // cost and token usage breakdown for billing and monitoring
        type: string; // category of token usage
        model: string; // model that generated the response
        amount: number; // total tokens consumed
        cost: number; // cost associated with token usage
    }[];
    via_ai_chat_service: boolean; // flag indicating whether message passed through the chat service layer
}
